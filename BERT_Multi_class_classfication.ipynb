{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "BERT_Multi_class_classfication.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijUIz_yfRZYy"
      },
      "source": [
        "import torch\n",
        "import re\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from transformers import BertForSequenceClassification\n",
        "from google.colab import drive\n",
        "import io\n",
        "df_rad = pd.read_csv(io.BytesIO(uploaded['radiology_reports_birads_score_STUDENTS_PRO.csv']))\n",
        "#df_rad =pd.read_csv('/Users/deepureddy/Desktop/REDI/radiology_reports_birads_score_STUDENTS_PRO.csv')\n",
        "df_rad = df_rad.apply(lambda x: x.astype(str).str.lower())\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"i\",1)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"ii\",2)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"iii\",3)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"iv\",4)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"v\",5)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"vi\",6)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"vii\",7)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"viii\",8)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"ix\",9)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"x\",10)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"een\",1)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"twee\",2)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"drie\",3)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"vier\",4)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"vijf\",5)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"zes\",6)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"zeven\",7)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"acht\",8)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"negen\",9)\n",
        "df_rad[\"BIRADS\"] = df_rad[\"BIRADS\"].replace(\"tien\",10)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('iva', 4)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('ivb', 4)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('ivc', 4)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('ivd', 4)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('4a', 4)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('4b', 4)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('4c', 4)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('4d', 4)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('0', 0)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('1', 1)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('2', 2)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('3', 3)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('4', 4)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('5', 5)\n",
        "df_rad['BIRADS'] = df_rad['BIRADS'].replace('6', 6)\n",
        "df_rad_1 = df_rad\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('dutch')\n",
        "stop.remove('geen')\n",
        "spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
        "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
        "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
        "              \"`\",\"{\",\"|\",\"}\",\"~\",\"–\",\"\\n\",'ii','iii',\"\\d\",\"Verslag:\", \"medische\", \"gegevens\"]\n",
        "for char in spec_chars:\n",
        "    df_rad_1['Report_MG'] = df_rad_1['Report_MG'].str.replace(char, ' ')\n",
        "    df_rad_1['Report_US'] = df_rad_1['Report_US'].str.replace(char, ' ')\n",
        "    df_rad_1['Report_MRI'] = df_rad_1['Report_MRI'].str.replace(char, ' ')\n",
        "df_rad_1['Report_MG'] = df_rad_1['Report_MG'].str.split(\"conclusie:\",expand=True)[0]\n",
        "df_rad_1['Report_MG'] = df_rad_1['Report_MG'].str.split(\"conclusie\",expand=True)[0]\n",
        "df_ploted = df_rad_1['BIRADS'].value_counts()\n",
        "df_ploted.plot.bar(x=\"test\", y=\"gest\", rot=100, title=\"BIRADS Data distrubtion\")\n",
        "df_rad_1.drop(df_rad_1.index[df_rad_1['BIRADS'] == 'nan'], inplace = True)\n",
        "df_rad_1.drop(df_rad_1.index[df_rad_1['BIRADS'] == '7'], inplace = True)\n",
        "df_rad_1.drop(df_rad_1.index[df_rad_1['BIRADS'] == '8'], inplace = True)\n",
        "df_rad_1.drop(df_rad_1.index[df_rad_1['BIRADS'] == '9'], inplace = True)\n",
        "df_ploted = df_rad_1['BIRADS'].value_counts()\n",
        "df_ploted.plot.bar(x=\"test\", y=\"gest\", rot=100, title=\"BIRADS Data distrubtion\")\n",
        "df_training = df_rad_1[['Id','Report_MG','BIRADS']]\n",
        "df_training['cleaned_text'] = df_training['Report_MG'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "df_training.drop(df_training.index[df_training['Report_MG'] == 'nan'], inplace = True)\n",
        "new_ploted = df_training['BIRADS'].value_counts()\n",
        "new_ploted.plot.bar(title=\"BIRADS Data distrubtion\")\n",
        "df_training['cleaned_text'] = df_training['Report_MG'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "df_training.head()\n",
        "df_main_data = df_training[['cleaned_text','BIRADS']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSk7kISUSswU"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxye70qyRe_3"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2DhEG2qRpec"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cJZhURfRsH1"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiafRVgzRZY2"
      },
      "source": [
        "df_main_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbPIRT9BRZY3"
      },
      "source": [
        "import numpy as np\n",
        "seq_len = 512\n",
        "num_samples = len(df_main_data)\n",
        "Xids =np.zeros((num_samples,seq_len))\n",
        "Xmask =np.zeros((num_samples,seq_len))\n",
        "Xids.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hauzu5mXRZY3"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('GroNLP/bert-base-dutch-cased')\n",
        "for i,cleaned_text in enumerate(df_main_data['cleaned_text']):\n",
        "    tokens = tokenizer.encode_plus(cleaned_text, max_length=seq_len, truncation = True,\n",
        "                                 padding ='max_length',add_special_tokens = True,return_tensors = 'tf')\n",
        "    Xids[i, :] = tokens['input_ids']\n",
        "    Xmask[i, :] = tokens['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm5bkR8XRZY3"
      },
      "source": [
        "Xids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiDgmtSGRZY4"
      },
      "source": [
        "Xmask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2b-z6NKRZY4"
      },
      "source": [
        "df_main_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDm6G78pRZY4"
      },
      "source": [
        "arr = pd.to_numeric(df_main_data['BIRADS'].values)\n",
        "arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgWoMKPRRZY5"
      },
      "source": [
        "labels = np.zeros((num_samples, arr.max()+1))\n",
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cap0dpxRZY5"
      },
      "source": [
        "#df_main_data['BIRADS'] = df_main_data['BIRADS'].astype(int)\n",
        "df_main_data['BIRADS'] = pd.to_numeric(df_main_data['BIRADS'])\n",
        "\n",
        "df_main_data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MqLgiugRZY5"
      },
      "source": [
        "labels[np.arange(num_samples), arr] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgH8r6lBRZY6"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqQS5YwZRZY6"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMr1Fz1lRZY6"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((Xids,Xmask,labels))\n",
        "dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD-KGvkZRZY6"
      },
      "source": [
        "labels[0, :].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmP6umfYRZY6"
      },
      "source": [
        "def map_func(input_ids, masks,labels):\n",
        "    return {'input_ids' :input_ids, 'attention_mask' : masks}, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQOKtshcRZY7"
      },
      "source": [
        "dataset = dataset.map(map_func)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byr3b8ihRZY7"
      },
      "source": [
        "dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kzA-DQ7RZY7"
      },
      "source": [
        "batch_size = 10\n",
        "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder = True)\n",
        "dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPcShgaJRZY7"
      },
      "source": [
        "split = 0.8\n",
        "size = int((num_samples/batch_size)*split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZSTeTcaRZY7"
      },
      "source": [
        "int((num_samples/batch_size)*split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoJ-dAQ1RZY8"
      },
      "source": [
        "train_ds = dataset.take(size)\n",
        "val_ds = dataset.skip(size)\n",
        "del dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8G53QmbRZY8"
      },
      "source": [
        "from transformers import TFAutoModel\n",
        "bert = TFAutoModel.from_pretrained('GroNLP/bert-base-dutch-cased')\n",
        "bert.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zs5U5puRZY8"
      },
      "source": [
        "input_ids = tf.keras.layers.Input(shape=(seq_len,), name = 'input_ids',dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(seq_len,), name = 'attention_mask',dtype='int32')\n",
        "embeddings = bert.bert(input_ids,mask)[1]\n",
        "x = tf.keras.layers.Dense(1024, activation = 'relu')(embeddings)\n",
        "y = tf.keras.layers.Dense(arr.max()+1, activation = 'softmax',name = 'outputs')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShpkqEGlRZY8"
      },
      "source": [
        "model = tf.keras.Model(inputs =[input_ids,mask], outputs = y)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTRbg_iuRZY8"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5, decay = 1e-6)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbf9dKtrRZY9"
      },
      "source": [
        "model.compile(optimizer=optimizer,loss =loss, metrics = [acc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9q5f5n9T4nV"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YUAhFC3RZY9"
      },
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = 8\n",
        ")\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(1,8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iPQ79A4RZY9"
      },
      "source": [
        "model.save('sentiment_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkKOnbVURZY9"
      },
      "source": [
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgsc8F5gRZY9"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('GroNLP/bert-base-dutch-cased')\n",
        "def pred_data(text):\n",
        "    tokens = tokenizer.encode_plus(text,max_length = 512, truncation = True, padding = 'max_length',\n",
        "                                  add_special_tokens = True,return_token_type_id = False, return_tensors = 'tf')\n",
        "    return {\n",
        "        'input_ids' : tf.cast(tokens['input_ids'],tf.float64),\n",
        "        'attention_mask' : tf.cast(tokens['attention_mask'],tf.float64)\n",
        "\n",
        "    }\n",
        "\n",
        "test = pred_data('aanhoudende pijnklachten linkerborst geen palpabele afwijkingen verslag mammografie volgens protocol ter vergelijk analoge onderzoek d d goed beoordeelbaar mammogram deels geïnvolueerd fibroglandulair weefsel acr classificatie geringe asymmetrie verdeling klierweefsel waarbij rechts lateraal druk gebied aanvullende detailopname gebied geen verdachte massa s densiteiten anderszins tevens geen verdachte massa s densiteiten geen architectuurverstoringen geen clusters microcalcificaties normaal beeld cutis subcutis alsmede mamilla beiderzijds axillae geen aanwijzingen pathologie conclusie normaal mammogram geen aanwijzingen maligniteit birads i')\n",
        "\n",
        "prob = model.predict(test)\n",
        "prob[0]\n",
        "\n",
        "import numpy as np\n",
        "Y_pred = np.argmax(prob[0])\n",
        "\n",
        "cf_matrix = confusion_matrix(y, y_pred,labels)\n",
        "print(cf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvbhvcQp7_ei"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}